src/: Contains all main scripts (tokenization logic, preprocessing, training, evaluation).
notebooks/: Jupyter notebooks for development, testing, and visualization.
data/: Sample datasets for running the tokenizer.
models/: Pretrained models (e.g., LSA embeddings).
results/: Stores benchmark results and comparisons with other tokenizers.
tests/: Unit tests to ensure correctness.
docs/: Documentation and contribution guidelines.
